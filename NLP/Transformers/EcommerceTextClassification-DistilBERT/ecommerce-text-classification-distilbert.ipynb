{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T18:31:17.846550Z",
     "iopub.status.busy": "2022-09-26T18:31:17.846088Z",
     "iopub.status.idle": "2022-09-26T18:31:20.766915Z",
     "shell.execute_reply": "2022-09-26T18:31:20.765905Z",
     "shell.execute_reply.started": "2022-09-26T18:31:17.846436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to ./csv/default-49d8b7a373d3213e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43521875a16a425d9dec1c3ad3fa2636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aae6556771d4688aa224a2eaaa6d55c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to ./csv/default-49d8b7a373d3213e/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "354b2accab5c413ab777855c356db7c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'description'],\n",
       "        num_rows: 50425\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ecommerceDataset = load_dataset('csv', data_files='../input/ecommerce-text-classification/ecommerceDataset.csv',cache_dir=\"./\", names=[\"label\", \"description\"])\n",
    "ecommerceDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T18:31:23.115795Z",
     "iopub.status.busy": "2022-09-26T18:31:23.115411Z",
     "iopub.status.idle": "2022-09-26T18:31:23.122906Z",
     "shell.execute_reply": "2022-09-26T18:31:23.121954Z",
     "shell.execute_reply.started": "2022-09-26T18:31:23.115757Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 'Household',\n",
       " 'description': 'Paper Plane Design Framed Wall Hanging Motivational Office Decor Art Prints (8.7 X 8.7 inch) - Set of 4 Painting made up in synthetic frame with uv textured print which gives multi effects and attracts towards it. This is an special series of paintings which makes your wall very beautiful and gives a royal touch. This painting is ready to hang, you would be proud to possess this unique painting that is a niche apart. We use only the most modern and efficient printing technology on our prints, with only the and inks and precision epson, roland and hp printers. This innovative hd printing technique results in durable and spectacular looking prints of the highest that last a lifetime. We print solely with top-notch 100% inks, to achieve brilliant and true colours. Due to their high level of uv resistance, our prints retain their beautiful colours for many years. Add colour and style to your living space with this digitally printed painting. Some are for pleasure and some for eternal bliss.so bring home this elegant print that is lushed with rich colors that makes it nothing but sheer elegance to be to your friends and family.it would be treasured forever by whoever your lucky recipient is. Liven up your place with these intriguing paintings that are high definition hd graphic digital prints for home, office or any room.'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecommerceDataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T18:31:24.046919Z",
     "iopub.status.busy": "2022-09-26T18:31:24.045894Z",
     "iopub.status.idle": "2022-09-26T18:31:24.137525Z",
     "shell.execute_reply": "2022-09-26T18:31:24.136506Z",
     "shell.execute_reply.started": "2022-09-26T18:31:24.046874Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Household</td>\n",
       "      <td>Paper Plane Design Framed Wall Hanging Motivat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Household</td>\n",
       "      <td>SAF 'Floral' Framed Painting (Wood, 30 inch x ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Household</td>\n",
       "      <td>SAF 'UV Textured Modern Art Print Framed' Pain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Household</td>\n",
       "      <td>SAF Flower Print Framed Painting (Synthetic, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Household</td>\n",
       "      <td>Incredible Gifts India Wooden Happy Birthday U...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                        description\n",
       "0  Household  Paper Plane Design Framed Wall Hanging Motivat...\n",
       "1  Household  SAF 'Floral' Framed Painting (Wood, 30 inch x ...\n",
       "2  Household  SAF 'UV Textured Modern Art Print Framed' Pain...\n",
       "3  Household  SAF Flower Print Framed Painting (Synthetic, 1...\n",
       "4  Household  Incredible Gifts India Wooden Happy Birthday U..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ecommerceDataset.set_format(type=\"pandas\")\n",
    "df = ecommerceDataset[\"train\"][:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T18:31:25.485961Z",
     "iopub.status.busy": "2022-09-26T18:31:25.485227Z",
     "iopub.status.idle": "2022-09-26T18:31:25.492802Z",
     "shell.execute_reply": "2022-09-26T18:31:25.491880Z",
     "shell.execute_reply.started": "2022-09-26T18:31:25.485923Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50425, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe Shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T18:31:32.371885Z",
     "iopub.status.busy": "2022-09-26T18:31:32.371506Z",
     "iopub.status.idle": "2022-09-26T18:31:32.388622Z",
     "shell.execute_reply": "2022-09-26T18:31:32.387509Z",
     "shell.execute_reply.started": "2022-09-26T18:31:32.371847Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label          0\n",
       "description    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking if null value exists\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T18:31:33.486409Z",
     "iopub.status.busy": "2022-09-26T18:31:33.485403Z",
     "iopub.status.idle": "2022-09-26T18:31:33.511705Z",
     "shell.execute_reply": "2022-09-26T18:31:33.510831Z",
     "shell.execute_reply.started": "2022-09-26T18:31:33.486371Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label          0\n",
       "description    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping the null rows\n",
    "df=df.dropna()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T18:31:41.417388Z",
     "iopub.status.busy": "2022-09-26T18:31:41.417026Z",
     "iopub.status.idle": "2022-09-26T18:31:41.444434Z",
     "shell.execute_reply": "2022-09-26T18:31:41.443512Z",
     "shell.execute_reply.started": "2022-09-26T18:31:41.417358Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books\n",
      "Clothing & Accessories\n",
      "Electronics\n",
      "Household\n"
     ]
    }
   ],
   "source": [
    "# Unique labels\n",
    "import numpy as np\n",
    "for label in np.unique(df['label']):\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T18:31:42.206715Z",
     "iopub.status.busy": "2022-09-26T18:31:42.205946Z",
     "iopub.status.idle": "2022-09-26T18:31:42.426314Z",
     "shell.execute_reply": "2022-09-26T18:31:42.425654Z",
     "shell.execute_reply.started": "2022-09-26T18:31:42.206678Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df[\"label\"].value_counts().plot.barh()\n",
    "plt.title(\"Frequency of classes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T18:31:42.761551Z",
     "iopub.status.busy": "2022-09-26T18:31:42.760799Z",
     "iopub.status.idle": "2022-09-26T18:31:43.110331Z",
     "shell.execute_reply": "2022-09-26T18:31:43.109366Z",
     "shell.execute_reply.started": "2022-09-26T18:31:42.761509Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Paper Plane Design Framed Wall Hanging Motivat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>SAF 'Floral' Framed Painting (Wood, 30 inch x ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>SAF 'UV Textured Modern Art Print Framed' Pain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>SAF Flower Print Framed Painting (Synthetic, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Incredible Gifts India Wooden Happy Birthday U...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                        description\n",
       "0      3  Paper Plane Design Framed Wall Hanging Motivat...\n",
       "1      3  SAF 'Floral' Framed Painting (Wood, 30 inch x ...\n",
       "2      3  SAF 'UV Textured Modern Art Print Framed' Pain...\n",
       "3      3  SAF Flower Print Framed Painting (Synthetic, 1...\n",
       "4      3  Incredible Gifts India Wooden Happy Birthday U..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode the labels into numeric\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['label'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T18:31:43.306420Z",
     "iopub.status.busy": "2022-09-26T18:31:43.305836Z",
     "iopub.status.idle": "2022-09-26T18:31:43.832288Z",
     "shell.execute_reply": "2022-09-26T18:31:43.831199Z",
     "shell.execute_reply.started": "2022-09-26T18:31:43.306379Z"
    }
   },
   "outputs": [],
   "source": [
    "# Text Preprocessing\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing.\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T18:31:43.907767Z",
     "iopub.status.busy": "2022-09-26T18:31:43.907268Z",
     "iopub.status.idle": "2022-09-26T18:31:46.333707Z",
     "shell.execute_reply": "2022-09-26T18:31:46.332598Z",
     "shell.execute_reply.started": "2022-09-26T18:31:43.907726Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>paper plane design framed wall hanging motivat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>saf floral framed painting wood  inch x  inch ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>saf uv textured modern art print framed painti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>saf flower print framed painting synthetic  in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>incredible gifts india wooden happy birthday u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                        description\n",
       "0      3  paper plane design framed wall hanging motivat...\n",
       "1      3  saf floral framed painting wood  inch x  inch ...\n",
       "2      3  saf uv textured modern art print framed painti...\n",
       "3      3  saf flower print framed painting synthetic  in...\n",
       "4      3  incredible gifts india wooden happy birthday u..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description'] = df['description'].apply(clean_text)\n",
    "df['description'] = df['description'].str.replace('\\d+', '')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T18:31:46.336393Z",
     "iopub.status.busy": "2022-09-26T18:31:46.336008Z",
     "iopub.status.idle": "2022-09-26T18:31:46.351902Z",
     "shell.execute_reply": "2022-09-26T18:31:46.351000Z",
     "shell.execute_reply.started": "2022-09-26T18:31:46.336356Z"
    }
   },
   "outputs": [],
   "source": [
    "descriptions = df[\"description\"].map(str).values.tolist()\n",
    "labels = df[\"label\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T18:31:46.355256Z",
     "iopub.status.busy": "2022-09-26T18:31:46.354428Z",
     "iopub.status.idle": "2022-09-26T18:32:18.964175Z",
     "shell.execute_reply": "2022-09-26T18:32:18.963053Z",
     "shell.execute_reply.started": "2022-09-26T18:31:46.355219Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789fac05655645ea9d3532591e72c760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e30855ced11747fc8fde031158410eee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel, DistilBertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import EarlyStoppingCallback\n",
    "import torch\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=4)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T18:32:18.969224Z",
     "iopub.status.busy": "2022-09-26T18:32:18.968106Z",
     "iopub.status.idle": "2022-09-26T18:32:26.409075Z",
     "shell.execute_reply": "2022-09-26T18:32:26.408142Z",
     "shell.execute_reply.started": "2022-09-26T18:32:18.969183Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c01498699844b05bb592f032b638165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c25e2d492daa43d3aa87a5bdb2b06691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(\n",
    "        \"distilbert-base-uncased\",\n",
    "        do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T18:32:26.410923Z",
     "iopub.status.busy": "2022-09-26T18:32:26.410552Z",
     "iopub.status.idle": "2022-09-26T18:32:26.469323Z",
     "shell.execute_reply": "2022-09-26T18:32:26.468495Z",
     "shell.execute_reply.started": "2022-09-26T18:32:26.410887Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(descriptions, labels, test_size=0.4, stratify=labels, random_state=42)\n",
    "x_valid, x_test, y_valid, y_test = train_test_split(x_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T18:32:26.471033Z",
     "iopub.status.busy": "2022-09-26T18:32:26.470651Z",
     "iopub.status.idle": "2022-09-26T18:32:26.476363Z",
     "shell.execute_reply": "2022-09-26T18:32:26.475475Z",
     "shell.execute_reply.started": "2022-09-26T18:32:26.470998Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_batch_tokenizer(tokenizer, dataset):\n",
    "    return tokenizer.batch_encode_plus(dataset,\n",
    "                                       max_length=256,\n",
    "                                       padding=True,\n",
    "                                       truncation=True,\n",
    "                                       add_special_tokens=True,\n",
    "                                       return_attention_mask=True,\n",
    "                                       return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T18:32:26.478426Z",
     "iopub.status.busy": "2022-09-26T18:32:26.477848Z",
     "iopub.status.idle": "2022-09-26T18:32:26.486303Z",
     "shell.execute_reply": "2022-09-26T18:32:26.485386Z",
     "shell.execute_reply.started": "2022-09-26T18:32:26.478390Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val\n",
    "                in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T18:32:26.488028Z",
     "iopub.status.busy": "2022-09-26T18:32:26.487668Z",
     "iopub.status.idle": "2022-09-26T18:34:38.796595Z",
     "shell.execute_reply": "2022-09-26T18:34:38.795477Z",
     "shell.execute_reply.started": "2022-09-26T18:32:26.487993Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train_tokens = get_batch_tokenizer(tokenizer, x_train)\n",
    "x_valid_tokens = get_batch_tokenizer(tokenizer, x_valid)\n",
    "x_test_tokens = get_batch_tokenizer(tokenizer, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T18:34:38.798753Z",
     "iopub.status.busy": "2022-09-26T18:34:38.798309Z",
     "iopub.status.idle": "2022-09-26T18:34:38.803944Z",
     "shell.execute_reply": "2022-09-26T18:34:38.802846Z",
     "shell.execute_reply.started": "2022-09-26T18:34:38.798717Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset(x_train_tokens, y_train)\n",
    "valid_dataset = Dataset(x_valid_tokens, y_valid)\n",
    "test_dataset = Dataset(x_test_tokens, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T18:36:03.687521Z",
     "iopub.status.busy": "2022-09-26T18:36:03.687087Z",
     "iopub.status.idle": "2022-09-26T18:36:03.695537Z",
     "shell.execute_reply": "2022-09-26T18:36:03.694507Z",
     "shell.execute_reply.started": "2022-09-26T18:36:03.687476Z"
    }
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(output_dir=\"output\",\n",
    "                            evaluation_strategy=\"epoch\",\n",
    "                            metric_for_best_model=\"f1\",\n",
    "                            save_strategy=\"epoch\",\n",
    "                            num_train_epochs=3,\n",
    "                            load_best_model_at_end=True\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T18:45:51.828242Z",
     "iopub.status.busy": "2022-09-26T18:45:51.827541Z",
     "iopub.status.idle": "2022-09-26T18:45:51.840229Z",
     "shell.execute_reply": "2022-09-26T18:45:51.838934Z",
     "shell.execute_reply.started": "2022-09-26T18:45:51.828201Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "def compute_metrics(p):\n",
    "    prediction, labels = p\n",
    "    preds_flat = np.argmax(prediction, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    f1 = f1_score(labels_flat, preds_flat, average='macro')\n",
    "    return {\"f1\": f1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T18:45:59.215325Z",
     "iopub.status.busy": "2022-09-26T18:45:59.214935Z",
     "iopub.status.idle": "2022-09-26T18:45:59.229210Z",
     "shell.execute_reply": "2022-09-26T18:45:59.227708Z",
     "shell.execute_reply.started": "2022-09-26T18:45:59.215291Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(args=args,\n",
    "                    model=model,\n",
    "                    train_dataset=train_dataset,\n",
    "                    eval_dataset=valid_dataset,\n",
    "                    compute_metrics=compute_metrics,\n",
    "                    callbacks=[EarlyStoppingCallback(\n",
    "                            early_stopping_patience=3)]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T18:46:00.078619Z",
     "iopub.status.busy": "2022-09-26T18:46:00.078230Z",
     "iopub.status.idle": "2022-09-26T19:09:44.061492Z",
     "shell.execute_reply": "2022-09-26T19:09:44.060516Z",
     "shell.execute_reply.started": "2022-09-26T18:46:00.078585Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 30254\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11346\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11346' max='11346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11346/11346 23:43, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.108200</td>\n",
       "      <td>0.170478</td>\n",
       "      <td>0.971199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.063700</td>\n",
       "      <td>0.138494</td>\n",
       "      <td>0.978867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.038100</td>\n",
       "      <td>0.141461</td>\n",
       "      <td>0.978557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 10085\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-3782\n",
      "Configuration saved in output/checkpoint-3782/config.json\n",
      "Model weights saved in output/checkpoint-3782/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10085\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-7564\n",
      "Configuration saved in output/checkpoint-7564/config.json\n",
      "Model weights saved in output/checkpoint-7564/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10085\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-11346\n",
      "Configuration saved in output/checkpoint-11346/config.json\n",
      "Model weights saved in output/checkpoint-11346/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from output/checkpoint-7564 (score: 0.9788667412805084).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=11346, training_loss=0.07179853039066901, metrics={'train_runtime': 1423.9494, 'train_samples_per_second': 63.74, 'train_steps_per_second': 7.968, 'total_flos': 6011717431652352.0, 'train_loss': 0.07179853039066901, 'epoch': 3.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T19:10:09.904162Z",
     "iopub.status.busy": "2022-09-26T19:10:09.903505Z",
     "iopub.status.idle": "2022-09-26T19:10:52.124269Z",
     "shell.execute_reply": "2022-09-26T19:10:52.123396Z",
     "shell.execute_reply.started": "2022-09-26T19:10:09.904122Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 10085\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1261' max='1261' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1261/1261 00:42]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(model=model)\n",
    "predictions = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T19:11:17.498586Z",
     "iopub.status.busy": "2022-09-26T19:11:17.498176Z",
     "iopub.status.idle": "2022-09-26T19:11:17.507839Z",
     "shell.execute_reply": "2022-09-26T19:11:17.506637Z",
     "shell.execute_reply.started": "2022-09-26T19:11:17.498554Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = np.argmax(predictions.predictions, axis=1).flatten()\n",
    "true_vals = predictions.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T19:11:22.767138Z",
     "iopub.status.busy": "2022-09-26T19:11:22.766433Z",
     "iopub.status.idle": "2022-09-26T19:11:22.797089Z",
     "shell.execute_reply": "2022-09-26T19:11:22.796129Z",
     "shell.execute_reply.started": "2022-09-26T19:11:22.767100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                 Books       0.98      0.98      0.98      2335\n",
      "Clothing & Accessories       0.99      0.98      0.98      1772\n",
      "           Electronics       0.98      0.97      0.97      2111\n",
      "             Household       0.98      0.99      0.98      3867\n",
      "\n",
      "              accuracy                           0.98     10085\n",
      "             macro avg       0.98      0.98      0.98     10085\n",
      "          weighted avg       0.98      0.98      0.98     10085\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(true_vals, preds, target_names=list(le.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
